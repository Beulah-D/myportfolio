<!DOCTYPE HTML>
<html>
<head>
    <title>Publications - Beulah Kannan Portfolio</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
    <!-- Font Awesome for icons -->
    <script src="https://kit.fontawesome.com/a076d05399.js" crossorigin="anonymous"></script>
</head>
<body class="is-preload">

    <!-- Wrapper -->
    <div id="wrapper">

        <!-- Header -->
        <header id="header">
            
        </header>

        <!-- Nav -->
        <nav id="nav">
            <ul class="links">
                <li><a href="index.html">INTRO</a></li>
                <li><a href="index.html">PROJECTS</a></li>
                <li><a href="experience.html">EXPERIENCE</a></li>
                <li class="active"><a href="publications.html">PUBLICATIONS</a></li>
            </ul>
        
        </nav>

        <!-- Main -->
        <div id="main">

            <!-- Publications Section -->
            <section class="post">
                <header class="major">
                    <h1>My Publications</h1>
                    <p>Explore my peer-reviewed research papers and technical articles.</p>
                </header>

                <!-- Publication 1 -->
                <article>
                    <h2>
                    
                            I-DLMI: Web Image Recommendation Using Deep Learning and Machine Intelligence
                
                        <a href="https://link.springer.com/chapter/10.1007/978-3-031-27409-1_24" target="_blank">
                            <i class="fas fa-external-link-alt" style="font-size: 0.8em; margin-left: 5px;"></i>
                        </a>
                    </h2>
                    <p>This paper introduces the I-DLMI framework, a semantic web image recommendation system for Web 3.0. It integrates knowledge from WikiData and YAGO for entity enrichment and uses LSTM for automatic classification. The system optimizes performance using semantic similarity computation and MapReduce with Pearson’s correlation coefficient, achieving high accuracy in recommending relevant images.
                        <br>Key Results: 96.02% precision, 98.19% recall, and 97.10% accuracy.</br>
                    </p>
                </article>

                <!-- Publication 2 -->
                <article>
                    <h2>
                    
                            WCMIVR: a web 3.0 compliant machine intelligence driven scheme for video recommendation
                    
                        <a href="https://link.springer.com/chapter/10.1007/978-3-031-27499-2_53" target="_blank">
                            <i class="fas fa-external-link-alt" style="font-size: 0.8em; margin-left: 5px;"></i>
                        </a>
                    </h2>
                    <p>The WCMIVR framework is a Web 3.0-compliant video recommendation system that integrates semantic knowledge for enhanced personalization. It employs TF-IDF for informative word extraction, Wikidata and Google Knowledge Graph API for query enrichment, and ontology alignment for feature selection. A logistic regression-based classifier is used to categorize video datasets, while Horn’s index, Twitter semantic similarity, and Jaccard similarity ensure relevance computation for ranking and recommendations.
                        <br>Key Results: 97.88% precision, 99.04% recall, 98.46% accuracy, and an FDR of 0.03, outperforming baseline models.</br></p>
                </article>

                <!-- Publication 3 -->
                <article>
                    <h2>
                    
                            RWNR: Radial Basis Feed Forward Neural Network Driven News Recommendation
                
                        <a href="https://link.springer.com/chapter/10.1007/978-3-031-47997-7_11" target="_blank">
                            <i class="fas fa-external-link-alt" style="font-size: 0.8em; margin-left: 5px;"></i>
                        </a>
                    </h2>
                    <p>This paper presents RWNR, a socially aware news recommendation system designed for Web 3.0. It uses a Radial Basis Feed Forward Neural Network (RBFNN) combined with Latent Dirichlet Allocation (LDA) and data from APIs like NewsAPI, Bloomberg, and Twitter. The system delivers personalized news recommendations by optimizing results using the Harmony Search Algorithm.
                        <br>Key Results: 96.09% recall, 91.19% F-measure, and 96.63% accuracy.</br></p>
                </article>
                <!-- Publication 4 -->
                <article>
                    <h2>
                    
                        OGIA: Ontology Integration and Generation Using Archaeology as a Domain
                
                        <a href="https://link.springer.com/chapter/10.1007/978-981-97-0975-5_2" target="_blank">
                            <i class="fas fa-external-link-alt" style="font-size: 0.8em; margin-left: 5px;"></i>
                        </a>
                    </h2>
                    <p>The OGIA framework focuses on ontology generation for specialized fields like archaeology. It enriches data using WikiData and DBpedia, employs TF-IDF for topic modeling, and uses Bi-LSTM for classification. Semantic reasoning is enhanced through Horn’s index, Twitter similarity, and evolutionary algorithms for optimized ontology creation.
                       <br> Key Results: 94.09% precision, 96.09% recall, and 95.09% accuracy.</br>
                        </p>
                </article>
                <!-- Publication 5 -->
                <article>
                    <h2>
                    
                        SADGF: Surveillance-based Anxiety Detection Using Gender-based Facial Emotion Recognition
                
                        <a href="https://ieeexplore.ieee.org/abstract/document/10029253" target="_blank">
                            <i class="fas fa-external-link-alt" style="font-size: 0.8em; margin-left: 5px;"></i>
                        </a>
                    </h2>
                    <p>The SADGF framework detects anxiety through gender-based facial emotion recognition using surveillance data. A CNN model is employed to classify gender and detect emotions such as happiness, anger, and sadness. This system aims to provide continuous monitoring for elderly care and mental health assessment in smart surveillance systems.
                        </p>
                </article>
                 <!-- Publication 6 -->
                 <article>
                    <h2>
                    
                        Vision Transformer-Based Forest Fire Detection for Smart Alert Systems
                
                        <a href="https://ieeexplore.ieee.org/abstract/document/10141387" target="_blank">
                            <i class="fas fa-external-link-alt" style="font-size: 0.8em; margin-left: 5px;"></i>
                        </a>
                    </h2>
                    <p>This paper introduces a forest fire detection system using Vision Transformers (ViT) for early detection and alerts. The system processes video feeds to detect fires and uses YOLO v3 for identifying humans in affected areas. Upon detection, it sends emergency alerts with location details via SMS, Email, and WhatsApp, enabling rapid response.
                        <br>Key Results: 98% fire detection accuracy, 83% human detection accuracy.</br>
                        </p>
                </article>

            </section>
        </div>

        <!-- Footer -->
        
    </div>

    <!-- Scripts -->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/main.js"></script>

</body>
</html>
